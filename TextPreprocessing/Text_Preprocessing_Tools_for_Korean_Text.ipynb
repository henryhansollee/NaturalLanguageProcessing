{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30a7d27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.307 Gb\n",
      "all cohesion probabilities was computed. # words = 223348\n",
      "all branching entropies was computed # words = 361598\n",
      "all accessor variety was computed # words = 361598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08838002913645132"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = '김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.'\n",
    "\n",
    "new_sent = sent.replace(\" \", '') # 띄어쓰기가 없는 문장 임의로 만들기\n",
    "# print(new_sent)\n",
    "\n",
    "from pykospacing import Spacing\n",
    "spacing = Spacing()\n",
    "kospacing_sent = spacing(new_sent) \n",
    "\n",
    "# print(sent)\n",
    "# print(kospacing_sent)\n",
    "\n",
    "from hanspell import spell_checker\n",
    "\n",
    "sent = \"맞춤법 틀리면 외 않되? 쓰고싶은대로쓰면돼지 \"\n",
    "spelled_sent = spell_checker.check(sent)\n",
    "\n",
    "hanspell_sent = spelled_sent.checked\n",
    "# print(hanspell_sent)\n",
    "\n",
    "spelled_sent = spell_checker.check(new_sent)\n",
    "\n",
    "hanspell_sent = spelled_sent.checked\n",
    "# print(hanspell_sent)\n",
    "# print(kospacing_sent) # 앞서 사용한 kospacing 패키지에서 얻은 결과\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "tokenizer = Okt()\n",
    "# print(tokenizer.morphs('에이비식스 이대휘 1월 최애돌 기부 요정'))\n",
    "\n",
    "import urllib.request\n",
    "from soynlp import DoublespaceLineCorpus\n",
    "from soynlp.word import WordExtractor\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt\", filename=\"2016-10-20.txt\")\n",
    "\n",
    "corpus = DoublespaceLineCorpus(\"2016-10-20.txt\")\n",
    "len(corpus)\n",
    "\n",
    "i = 0\n",
    "for document in corpus:\n",
    "  if len(document) > 0:\n",
    "#     print(document)\n",
    "    i = i+1\n",
    "  if i == 3:\n",
    "    break\n",
    "\n",
    "word_extractor = WordExtractor()\n",
    "word_extractor.train(corpus)\n",
    "word_score_table = word_extractor.extract()\n",
    "\n",
    "word_score_table[\"반포한\"].cohesion_forward\n",
    "word_score_table[\"반포한강\"].cohesion_forward\n",
    "word_score_table[\"반포한강공\"].cohesion_forward\n",
    "word_score_table[\"반포한강공원\"].cohesion_forward\n",
    "word_score_table[\"반포한강공원에\"].cohesion_forward\n",
    "\n",
    "word_score_table[\"디스\"].right_branching_entropy\n",
    "word_score_table[\"디스플\"].right_branching_entropy\n",
    "word_score_table[\"디스플레\"].right_branching_entropy\n",
    "word_score_table[\"디스플레이\"].right_branching_entropy\n",
    "\n",
    "from soynlp.tokenizer import LTokenizer\n",
    "\n",
    "scores = {word:score.cohesion_forward for word, score in word_score_table.items()}\n",
    "l_tokenizer = LTokenizer(scores=scores)\n",
    "l_tokenizer.tokenize(\"국제사회와 우리의 노력들로 범죄를 척결하자\", flatten=False)\n",
    "\n",
    "from soynlp.tokenizer import MaxScoreTokenizer\n",
    "\n",
    "maxscore_tokenizer = MaxScoreTokenizer(scores=scores)\n",
    "maxscore_tokenizer.tokenize(\"국제사회와우리의노력들로범죄를척결하자\")\n",
    "\n",
    "from soynlp.normalizer import *\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠ', num_repeats=2))\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠ', num_repeats=2))\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠ', num_repeats=2))\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠ', num_repeats=2))\n",
    "\n",
    "print(repeat_normalize('와하하하하하하하하하핫', num_repeats=2))\n",
    "print(repeat_normalize('와하하하하하하핫', num_repeats=2))\n",
    "print(repeat_normalize('와하하하하핫', num_repeats=2))\n",
    "\n",
    "from ckonlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "twitter.morphs('은경이는 사무실로 갔습니다.')\n",
    "\n",
    "twitter.add_dictionary('은경이', 'Noun')\n",
    "twitter.morphs('은경이는 사무실로 갔습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dddc800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
